\begin{figure*}
\begin{code}
    forward_sol :: LastNode l => (forall a . Fuel -> Maybe a -> Maybe a) -> RewritingDepth -> PassName 
                -> BlockEnv a -> ForwardTransfers m l a -> ForwardRewrites m l a
                -> a -> Graph m l -> Fuel
                -> DFM a (ForwardFixedPoint m l a (), Fuel)
    forward_sol squash depth name start_facts transfers rewrites = fixed_point
     where fixed_point in_fact g fuel =
             do { setAllFacts start_facts
                ; (a, fuel) <- solve getExitFact in_fact g fuel
                ; ...
                ; return (... a ..., fuel)
                }

           solve :: DFM a b -> a -> Graph m l -> Fuel -> DFM a (b, Fuel)
           solve finish in_fact g fuel =
             let blocks = G.postorder_dfs g
                 set_successor_facts (Block id tail) fuel =
                   do { idfact <- getFact id
                      ; (last_outs, fuel) <-
                          ... solve_tail (ft_first_out transfers id idfact) tail fuel ...
                      ; set_or_save last_outs
                      ; return fuel }

             in  do { fuel <- run "forward" name set_successor_facts blocks fuel
                    ; b <- finish
                    ; return (b, fuel) }

           solve_tail in' (G.ZTail m t) fuel =
             case squash fuel $ fr_middle rewrites m in' of
               Nothing -> solve_tail (ft_middle_out transfers m in') t fuel
               Just g -> do { g <- areturn g
                            ; (a, fuel) <- subAnalysis' $
                                 case depth of
                                   RewriteDeep -> solve getExitFact in' g (oneLessFuel fuel)
                                   RewriteShallow -> do { a <- anal_f getExitFact in' g
                                                        ; return (a, oneLessFuel fuel) }
                            ; solve_tail a t fuel
                            }
           ...
\end{code}
\caption{Excerpts from the forward solver}
\figlabel{solver-excerpts}
\end{figure*}



\section{The Dataflow Engine}
\seclabel{engine}
\seclabel{dfengine}

\simon{Need a linking sentence like ``So far we have discussed clients of 
our library.  Now we turn our attention to the implementation of the
library itself.''  Yes, you'll want to use different vocabulary!}

The dataflow engine is implemented in two layers.
The lower layer comprises the \emph{dataflow monad} and the \emph{fuel monad}.
The dataflow monad keeps track of the values of dataflow facts as the
engine iterates; the fuel monad provides a way to suppress
optimization selectively in order to isolate faults \cite{whalley:isolation}.
%
The upper layer is divided into four parts:
a forward solver, a forward rewriter,
a backward solver, and a backward rewriter.

Despite the implicit claim in the title of this paper,
the dataflow engine is not simple.
The benefit of our design is that the \emph{interface} to the dataflow
engine (lattice, transfer functions, rewriting functions) is simple,
and as shown above, compiler passes written \emph{using} the engine
are very simple indeed.
But~the engine itself is complex.

Most of the complexity in the dataflow engine arises because we
implement the ambitious algorithm of
\citet{lerner-grove-chambers:2002}, who write
\begin{quote}
\emph{Previous efforts to exploit [the mutually beneficial
interactions of dataflow analyses] either (1)~iteratively performed
each individual analysis until no further improvements are discovered
or (2)~developed [handwritten] ``super-analyses'' that manually
combine conceptually separate analyses. We have devised a new approach
that allows analyses to be defined independently while still enabling
them to be combined automatically and profitably. Our approach avoids
the loss of precision associated with iterating individual analyses
and the implementation difficulties of manually writing a
super-analysis.}
\end{quote}
Adapting this work to a purely functional setting results in an
implementation that is significantly simpler than the original.
We~sketch that implementation below.


%%  Note that the dataflow engine is the only part of the system that is
%%  hard to get right---this is where all the hair is.
%%  Prime benefit of our system is that once this is right, everything is
%%  easy (and indeed is just logic, strongest postcondition, or weakest
%%  precondition). 
%%  

\subsection{Throttling the dataflow engine using ``optimization
  fuel''}

\seclabel{vpoiso}

We have extended Lerner, Grove, and Chambers's algorithm with
Whalley's \citeyearpar{whalley:isolation} algorithm for isolating
faults.
Whalley's algorithm is used to test a faulty optimizer by automatically
finding the first program transformation that introduces a fault.
It works by giving the optimizer a finite supply of \emph{optimization
fuel}.
Each time a rewrite function proposes to replace a node, one unit of fuel is
consumed.
When the optimizer runs out of fuel, further rewrites are suppressed.
In~normal operation, the optimizer has unlimited fuel, but during
debugging, faults can be isolated quickly by doing a binary search on
the size of the fuel supply.


\subsection{The forward solver}

\simon{By this time I'm getting tired.  This section has a lot of nitty
gritty detail but, becuase it is explaining a complex implementation,
it is necessarily incomplete. So the question in my mind is this: what
does the reader learn from the rest of Section 7?  What new insights
are gained, beyond a quick sketch of a particular implementation?
For example, is it notably simpler than the OCaml version or Chambers's version?
If so, what led to this simplicity?

Give the time, one possibility would be to trim Section 7 down a lot,
which would give more space (and time!) for clarifying remarks earlier.
(We are already up to page 14.)

There are quite a few Simon comments in what follows, but I gave it
much less time per line than earlier stuff.}

\remark{It's dramatically simpler than Chambers's stuff because it's
  purely functional and it's polymorphic.  For the OCaml stuff I'd
  have to compare more carefully.
I'd like John to weigh in here---I~understood him to say that if we
  don't deliver the implementation of the dataflow engine, we're
  omitting a critical part of our design.}
\simon{PS: currently the polymorphism is mentioned iter alia, but
is never the focus; yet it's one of our major claims, so it deserves
explicit treatment.  Not necessarily here.}

In implementing the dataflow engine, our primary tactic has been to
minimize duplicate and near-duplicate code.
To~that end, \emph{the dataflow engine implements only composed
analysis and transformation}.
Pure analysis is implemented as a special case in which no node is
ever rewritten.
As explained by \citet{lerner-grove-chambers:2002}, a~composed
analysis is implemented in two phases:
\begin{itemize}
\item
In the first phase, when a rewrite function proposes to replace a
node, the replacement graph is analyzed recursively, and the results
of that analysis are used as the new dataflow
fact(s) flowing out of the original node.
But \emph{the original node is not replaced}; indeed, the replacement
graph is abandoned, and only the facts remain.
If,~during iteration, the original node is analyzed again, perhaps
with a more conservative input fact, the rewrite function may propose
a different replacement or even no replacement at all.
This phase is called the \emph{solver}.
The solve computes a fixed point of the dataflow analysis
\emph{as if} nodes were replaced, while avoiding ever replacing a node
unsafely.
\simon{There rewrite functions must presumably satisfy
some monotonicity property.  Something like: given a more informative
fact, the rewrite function will rewrite a node to a more informative graph
(in the fact lattice.).
\textbf{NR}: actually the only obligation of the rewrite function is
to preserve observable behavior.  There's no requirement that it be
monotonic or indeed that it do anything useful.  It just has to
preserve semantics (and be a pure function of course).
\textbf{SLPJ} In that case I think I could cook up a program that
would never reach a fixpoint. Imagine a liveness analysis with a loop;
x is initially unused anywhere.
At some assignment node inside the loop, the rewriter behaves as follows: 
if (and only if) x is dead downstream, 
make it alive by rewriting the assignment to mention x.
Now in each successive iteration x will go live/dead/live/dead etc.  I
maintain my claim that rewrite functions must satisfy some monotonicity property.q
}
\item
Once the solver is complete, the resulting fixed point is sound,
and the facts in the fixed point are used by the second phase, in which
no dataflow facts change, but
each replacement proposed by a rewriting function is actually
performed.
This phase is called the \emph{rewriter}.
\end{itemize}
\simon{These bullets address a chunk of my earlier questions in 
Section 6. But they are absolutely necessary to understand the \emph{specification}
of the analysis+rewrited function, are they not?  
If it's possible to specify the analysis+rewrite function more abstractly,
then let's do that; if this IS the spec, then we might consider putting it earlier.
\textbf{NR}: I think this is the spec, and I~agree it would be good to
have earlier.}



\begin{figure*}
%%  forward_rew
%%          :: forall m l a . 
%%             (DebugNodes m l, LastNode l, Outputable a)
%%          => (forall a . Fuel -> Maybe a -> Maybe a)
%%          -> RewritingDepth
%%          -> BlockEnv a
%%          -> PassName
%%          -> ForwardTransfers m l a
%%          -> ForwardRewrites m l a
%%          -> a
%%          -> Graph m l
%%          -> Fuel
%%          -> DFM a (ForwardFixedPoint m l a (Graph m l), Fuel)
%%  forward_rew squash depth xstart_facts name transfers rewrites in_factx gx fuelx = fixed_pt_and_fuel
%%    where
%%      fixed_pt_and_fuel =
%%          do { (a, g, fuel) <- rewrite xstart_facts getExitFact in_factx gx fuelx
%%             ; facts <- getAllFacts
%%             ; let fp = ... facts ... g ...
%%             ; return (fp, fuel)
%%             }
%%  
\begin{code}
      ...
    rewrite :: BlockEnv a -> DFM a b -> a -> Graph m l -> Fuel -> DFM a (b, Graph m l, Fuel)
    rewrite start finish in_fact g fuel =
      let Graph eid blockenv = g
          blocks = G.postorder_dfs_from blockenv entry
      in do { forward_sol squash depth name start transfers rewrites in_fact g fuel
            ; (rewritten, fuel) <- rewrite_blocks blocks emptyBlockEnv fuel
            ; a <- finish
            ; return (a, Graph eid rewritten, fuel)
            }

      ...

    rewrite_blocks (Block id t : bs) rewritten fuel =
      ... rew_tail h (ft_first_out transfers id a) t rewritten fuel ...
    rewrite_blocks [] rewritten fuel = return (rewritten, fuel)

    rew_tail head in' (G.ZTail m t) rewritten fuel =
      case squash fuel $ fr_middle rewrites m in' of
        Nothing -> rew_tail (G.ZHead head m) (ft_middle_out transfers m in') t rewritten fuel
        Just g -> do { markGraphRewritten
                     ; g <- areturn g
                     ; (a, g, fuel) <- inner_rew getExitFact in' g fuel
                     ; let (blocks, h) = G.splice_head' head g
                     ; rew_tail h a t (blocks `plusBlockEnv` rewritten) fuel }
\end{code}
\caption{Excerpts from the forward rewriter}
\figlabel{rewriter-excerpts}
\end{figure*}

In \citeyearnopar{ramsey-dias:applicative-flow-graph}, two of us
(\citeauthor{ramsey-dias:applicative-flow-graph}) presented
implementations in Objective Caml of a backward solver and rewriter.
Here, then, as a complement, we sketch implementations of the forward
solver and rewriter used in~GHC.

\figref{solver-excerpts} shows key excerpts from the forward solver 
@forward_sol@, which is the function used to implement
@zdfSolveFwd@.\remark{check spelling}
As~it is also used to solve subgraphs and to help the rewriter, it
takes a few more parameters:
\remark{If it can be done before submitting the paper, I really want
  to write a version of ZipDataflow that operates on LGraphs, just so
  I can be sure the code is right.}
\begin{itemize}
\item
An analysis of a subgraph starts with known facts, not bottom facts.
These facts are stored in parameter
@start_facts@.\remark{bletch---no parallel structure}
\item
The parameter @squash@ is used to suppress rewriting, either because
the solver is implementing a pure analysis, or because the optimizer
is out of fuel. 
\simon{Or because the analysis has not yet reached a fixpoint,
so we discard?
\textbf{NR}:
 Nope, no fixed points here. The rewritten graph (Just g) is 
\emph{always} discarded after computing the new fact.
I~would say this is obvious from the code except nothing about the
code is obvious.
Need anything be said in the text?
\textbf{SLPJ}: well we earlier say ``In the first phase, 
when a rewrite function proposes to replace a
node, ...the original node is not replaced'', which sounds like squashing
to me.  Maybe just rephrase that earlier bullet to nuke the remarks
about ``node not replaced'' and instead say that after
each iteration that does \emph{not} reach a fixpoint, the entire rewritten
graph is discarded.
}
The @fuel@ parameter represents the amount of fuel remaining.
It~is last because the fuel abstraction works with functions of type
@Fuel -> (a, Fuel)@.
\end{itemize}
A~fixed point is computed by initializing the facts using
@setAllFacts@, which is an operation in the dataflow monad.
\simon{I think it would help to list the operations of the monad. 
E.g. How should I think of @setAllFacts@ for example? Perhaps it's a state monad, whose
state includes a mapping from @BlockId@ to fact, and @setAllFacts@ initialises this
mapping?
\textbf{NR}:
I~had written a whole section on the monad, which was interminable
and seemed peripheral to the main point.  If we had the space I would
definitely go for a figure giving the operations mentioned here. 
I'm not sure we want to use our space that way, however.  It's a conundrum.
}
Function @solve@, also sketched in \figref{solver-excerpts}, finds a
fixed point and returns a pair containing the exit fact and the
remaining fuel supply.
This fact, plus other state extracted from the dataflow monad, are
used to create a fixed point.

\simon{@solve@ transforms the @Fuel@.  But isn't @Fuel@ part of the dataflow monad?
Is @DFMonad@ in the type of @zdfRewriteFwd@ the same as @DFM@ in this
figure?
\textbf{NR}:  Sadly not.  Is @DFMonad@ in the type of @zdfRewriteFwd@
is the composition of @DFM@ with @Fuel -> (a, Fuel)@.
I~fear we are trying to cram 10~pounds of information into a 5-pound sack.
}
 
Function @solve@ is higher-order: 
when solving a graph that ``falls through,'' 
the @finish@ parameter is @getExitFact@;
when solving a graph that ends in a control transfer,
the @finish@ parameter is @lastOutFacts@. \simon{This is the first mention
of the possiblity of a graph that ``falls through''.  After all this time,
I'm still not sure what it means, and the reader may be in a similar
state.
\textbf{NR}: Here's an operational approximation: a graph ``falls
through'' if it can be written @g <*> mkMiddle m@.  Does this help
you, at least?
}
Both @getExitFact@ and @lastOutFacts@ are operations in the dataflow
monad.

Function @solve@ takes a graph and does a postorder depth-first traversal 
to get a list of reachable blocks in~@blocks@.  
\remark{It's the @LastNode l@ constraint that makes it possible to
  find the successors of the last nodes and thereby to do the graph traversal.}
It then applies a higher-order @run@ function,
not shown here,
% And don't you dare ask for its type.  The type of run would make you
% vomit.  ---NR
which repeatedly runs
@set_successor_facts@ on @blocks@ in order until the internal facts
stop changing.
Although any order will result in a correct fixed point,
postorder depth-first order hastens convergence of forward dataflow
analyses---often just a few iterations suffice.



To understand the rest of the solver, you must understand the
representation of basic blocks.
A~basic block is a sequence beginning with a first node, continuing
with zero or more middle nodes, and ending in a last node.
A~first node contains only a unique identifier of type @BlockId@; the
types of middle and last nodes are parameters.
A~sequence of middle nodes followed by a last node is reresented by a
value of type @ZTail m l@, where @m@~and~@l@
are the types of middle and last nodes:
\begin{code}
data ZTail m l = ZLast (ZLast l) | ZTail m (ZTail m l)
\end{code}
The type @ZLast l@ extends~@l@ with an additional case, @LastExit@,
which represents a subgraph that ends not in a control transfer but by
``falling off the end.''
A~block is the first node followed by the tail:
\begin{code}
data Block m l = Block BlockId (ZTail m l)
\end{code}

Function @set_successor_facts@ walks a basic block from first node to
last node, using and updating the state maintained by
the dataflow monad.
The initial fact is the fact associated with the block's identifier,
extracted using @getFact@, which has type @BlockId -> DFM a a@.
Function @solve_tail@ walks the block and computes @last_outs@, which
gives the new facts to be propagated to the successors of the blocks,
as defined in \figref{transfers}.
Function @set_or_save@ updates the facts in the dataflow monad,
and finally @set_successor_facts@ returns the remaining fuel.

The workhorse of the analysis is @solve_tail@, which handles three
cases: a middle node, a last node, and ``falling off the end.''
\figref{solver-excerpts} shows only the code for the middle node.
The first step is present the incoming fact~@in'@ and the middle
node~@m@ to the approriate rewrite function.
If~that function returns @Nothing@, or if the value is squashed to
@Nothing@,\footnote
{@squash fuel a@ returns @Nothing@ if @a@~is @Nothing@, if @fuel@~is
  exhausted, or if we are running @zdfSolveFwd@, which uses no rewrite
  functions.
%In~the last case, lazy evaluation guarantees that @rewrites@ is not
%evaluated. 
}
In~that case @solve_tail@ simply calls the transfer function
@ft_middle_out transfers@ and continues with the next node.



The interesting case occurs when the rewrite function 
@fr_middle rewrites@
proposes a replacement graph~@g@.
\remark{Orphaned text:
and
a list of facts that hold on edges leaving the graph, which is  
 extracted using function @zdfFpLastOuts@.
\iffalse %%% WRONG -- it's the @goto@ that does this...
In the example above, when the subgraph
@z = 7 + y@ is analyzed, @zdfFpLastOuts@ will contain
the pair $(@L2@, @x == 7@ \land @y == 8@)$.
\fi
}
\begin{enumerate}
\item
Using the monadic
function @areturn@, the abstract graph~@g@ is given a supply of fresh
labels and is 
converted to internal form, also called~@g@. 
\item
If we are doing \emph{deep} rewriting, @g@~may be further rewritten,
so we call @solve@ recursively after removing one unit of fuel.
Graph~@g@ replaces a middle node, so we expect @g@ to fall off the
end, and therefore we want @solve@ to extract the exit fact.
\item
If we are doing \emph{shallow} rewriting,  new graph~@g@ must not be
rewritten, but we must still find a fixed point of the transfer
equations.
We compute that fixed point using @anal_f@, which  recursively calls
@forward_sol@ using the @squash@ function
@\ _ _ -> Nothing@, 
thereby doing no rewriting and consuming no fuel.\remark{Line number
  to where squash is used}
\end{enumerate}
Whether rewriting is shallow or deep, the new graph~@g@ is analyzed as
a ``sub-analysis'' in the dataflow monad, which means it has fresh
state for tracking facts and deciding whether analysis has reached a
fixed point.
State changes made in a sub-analysis cannot be observed by the outer
analysis. 
In~fact, after the sub-analysis all the new state \emph{and the new
  graph} are discarded.
All~that is kept is the new dataflow fact~@a@ and the diminished
supply of fuel.
Function @solve_tail@ continues tail-recursively solving~@t@.
The only difference between rewriting \remark{line number} and not
rewriting \remark{line number} is the
\emph{fact} and the \emph{fuel} passed to the tail call.

The full implementations of @solve@ and @solve_tail@, which are
included in a supplement to this paper, contain similar code which may
rewrite first nodes and last nodes and sub-analyze the replacement
graphs. 


%%\begin{itemize}
%%\item
%%\item
%%The internal @solve@ function is higher-order in the parameter
%%@finish@, which extracts from the dataflow monad either the unique
%%exit fact or the set of @LastOuts@, depending on context.
%%\item
%%The function @set_or_save@ calls @setFact@ for @BlockId@s located
%%within graph~@g@ and calls @addLastOutFact@ for @BlockId@s located
%%outside graph~@g@.
%%\end{itemize}



\subsection{The forward rewriter}

The core of the rewriter is shown in \figref{rewriter-excerpts}.
A~graph~@g@ to be rewritten is reprsented by a finite map from  @BlockId@
  to basic block, together with the @BlockId@ of the entry block:
\begin{code}
data Graph m l = Graph BlockId (BlockEnv (Block m l))
\end{code}
The function @rewrite@ first calls @forward_sol@ to iterate to a fixed
point.
At~this point, the facts stored in the dataflow monad can safely be
used for rewriting.
The work is done by @rewrite_blocks@; the monadic action @finish@
extracts any value of interest; and that value is returned together
with the rewritten graph and the remaining fuel.

The actual rewriting is done by @rewrite_blocks@, whose second parameter is
an accumulating parameter which carries a finite map containing those
blocks which have been fully rewritten.
As~above, we show only the code relevant to rewriting middle codes;
code for first nodes and last nodes is similar.
The @rew_tail@ function uses exactly the same test as in the solver:
it scrutinizes
\begin{verbatim}
   squash fuel $ fr_middle rewrites m in'
\end{verbatim}
If there is no rewriting, the action taken is almost the same, but
there is an additional accumulating parameter, @head@, which stores
the fragment of the basic block leading up to the node~@m@ which is
a candidate for rewriting.
To~store this fragment, we use type @ZHead m@, which makes the
nearest node the easiest to access; we append~@m@ to the
fragment~@head@ by forming @ZHead head m@:
\begin{verbatim} 
data ZHead m = ZFirst BlockId | ZHead (ZHead m) m
\end{verbatim}

The interesting case is where the middle node~@m@ is rewritten into
the replacement graph~@g@. \remark{line number}
We~first mark the graph as rewritten, so that whatever called this
pass may know that the graph has changed.
As~before, we convert~@g@ by supplying it with fresh labels.
We then call @inner_rew@, which calls @forward_sol@ when rewriting
shallowly (i.e., not rewriting~@g@) and calls @rewrite@ recursively
when rewriting deeply.
Finally, the rewritten graph, newly rebound to the name~@g@, is
spliced onto the head of the block, producing a new head~@h@ and a set
of fully rewritten blocks~@blocks@.
The splicing algorithm is described by
\citet{ramsey-dias:applicative-control-flow}. 
The new head~@h@ replaces @head@, and @blocks@ is added to the
accumulating parameter @rewritten@.
Function @rew_tail@ continues with the next node by making a tail call
to rewrite~@t@.






%%  \subsection{The dataflow monad}
%%  
%%  The primary purpose of the dataflow monad is to keep track of 
%%  dataflow facts as the engine iterates.
%%  Dataflow facts are found in three places:
%%  \begin{itemize}
%%  \item
%%  There is a dataflow fact associated with every labelled basic block in
%%  the current graph;
%%  the dataflow monad maintains this association in a finite map.
%%  The functions @getFact@ and @setFact@ query and update this map.
%%  \item
%%  The current graph may be a subgraph of a larger graph, in which case a
%%  forward dataflow pass may produce dataflow facts that flow to labelled
%%  blocks that are outside the current graph.
%%  These facts must be retained and propagated even if the current graph
%%  is abandoned; such facts are added with @addLastOutFact@ and recovered
%%  with @bareLastOuts@.
%%  \item
%%  Finally, a foraward dataflow pass over a subgraph may propagate a fact forward by
%%  ``falling off the end;'' such a fact is set with @setExitFact@ and
%%  recovered with @getExitFact@.
%%  \end{itemize}
%%  In addition to keeping track of facts, 
%%  the dataflow monad provides a number of other facilities to manage
%%  changes in state as graphs are rewritten and facts climb the dataflow
%%  lattice:
%%  \begin{itemize}
%%  \item
%%  The monad keeps track of whether any fact has changed.
%%  \item
%%  It provides a @subanalysis@ function which makes it possible to
%%   analyze a subgraph using the current set of facts, then discard any
%%   changes in state that may have resulted from the analysis of the
%%   subgraph.
%%  \item
%%  It provides a supply of fresh @BlockId@s, which are available for use
%%  by rewrite functions.
%%  \item
%%  It tracks the supply of \emph{optimization fuel}.
%%  As~shown below, when fuel runs out, the dataflow engine stops
%%  calling rewriting functions, effectively halting optimization.
%%  Binary search on the size of the fuel supply enables the compiler to
%%  identify unsound rewrites quickly \cite{whalley:isolation}.
%%  \end{itemize}








